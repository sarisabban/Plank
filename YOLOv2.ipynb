{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cPkBPFUSrLWh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#YOLOv2 Protist Image Classifier Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "bHvzApV0W5xr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Start\n",
        "\n",
        "**Environment Setup**\n",
        "\n",
        "Download and extract the dataset, install dependencies,  setup the neural network, and then train it."
      ]
    },
    {
      "metadata": {
        "id": "L0JZgbGpD0AO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/3qm7xi12bbxgje7/dataset.tar.bz2?dl=0\n",
        "!tar -jxvf dataset.tar.bz2?dl=0\n",
        "!rm dataset.tar.bz2?dl=0\n",
        "!pip3 install imgaug\n",
        "\n",
        "#!/usr/bin/python3\n",
        "\n",
        "'''\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2017 Ngoc Anh Huynh\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "\n",
        "This script is modified from: https://github.com/experiencor/keras-yolo2\n",
        "'''\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import copy\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.models import Model\n",
        "from keras.utils import Sequence\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D\n",
        "\n",
        "config = {\"model\":{\n",
        "\t\t\t\"labels\":               [\"Cell\"],\n",
        "\t\t\t\"input_size\":           416,\n",
        "\t\t\t\"anchors\":              [0.57273, 0.677385, 1.87446,\n",
        "\t\t\t\t\t\t\t\t\t2.06253, 3.33843, 5.47434,\n",
        "\t\t\t\t\t\t\t\t\t7.88282, 3.52778, 9.77052,\n",
        "\t\t\t\t\t\t\t\t\t9.16828],\n",
        "\t\t\t\"max_box_per_image\":    10,},\n",
        "\t\t\"train\":{\n",
        "\t\t\t\"train_image_folder\":   \"./dataset/Images/\",\n",
        "\t\t\t\"train_annot_folder\":   \"./dataset/Annotations/\",\n",
        "\t\t\t\"saved_weights_name\":   \"./cell.h5\",\n",
        "\t\t\t\"train_times\":          8,\n",
        "\t\t\t\"batch_size\":           16,\n",
        "\t\t\t\"learning_rate\":        1e-4,\n",
        "\t\t\t\"nb_epochs\":            1000,\n",
        "\t\t\t\"warmup_epochs\":        0,\n",
        "\t\t\t\"object_scale\":         5.0 ,\n",
        "\t\t\t\"no_object_scale\":      1.0,\n",
        "\t\t\t\"coord_scale\":          1.0,\n",
        "\t\t\t\"class_scale\":          1.0,\n",
        "\t\t\t\"debug\":                True},\n",
        "\t\t\"valid\":{\n",
        "\t\t\t\"valid_image_folder\":   \"\",\n",
        "\t\t\t\"valid_annot_folder\":   \"\",\n",
        "\t\t\t\"valid_times\":          1}}\n",
        "\n",
        "class BaseFeatureExtractor(object):\n",
        "\tdef __init__(self, input_size):\n",
        "\t\traise NotImplementedError(\"error message\")\n",
        "\tdef normalize(self, image):\n",
        "\t\traise NotImplementedError(\"error message\")\n",
        "\tdef get_output_shape(self):\n",
        "\t\treturn self.feature_extractor.get_output_shape_at(-1)[1:3]\n",
        "\tdef extract(self, input_image):\n",
        "\t\treturn self.feature_extractor(input_image)\n",
        "\n",
        "class FullYoloFeature(BaseFeatureExtractor):\n",
        "\tdef __init__(self, input_size):\n",
        "\t\tinput_image = Input(shape=(input_size, input_size, 3))\n",
        "\t\tdef space_to_depth_x2(x):\n",
        "\t\t\treturn tf.space_to_depth(x, block_size=2)\n",
        "\t\tx = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "\t\tx = BatchNormalization(name='norm_1')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\t\tx = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_2')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\t\tx = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_3')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_4')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_5')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\t\tx = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_6')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_7')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_8')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\t\tx = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_9')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_10')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_11')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_12')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_13')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tskip_connection = x\n",
        "\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\t\tx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_14')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_15')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_16')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_17')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_18')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_19')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_20')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tskip_connection = Conv2D(64, (1,1),\n",
        "\t\t\t\t\t\t\t\tstrides=(1,1),\n",
        "\t\t\t\t\t\t\t\tpadding='same',\n",
        "\t\t\t\t\t\t\t\tname='conv_21',\n",
        "\t\t\t\t\t\t\t\tuse_bias=False)(skip_connection)\n",
        "\t\tskip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "\t\tskip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "\t\tskip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\t\tx = concatenate([skip_connection, x])\n",
        "\t\tx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
        "\t\tx = BatchNormalization(name='norm_22')(x)\n",
        "\t\tx = LeakyReLU(alpha=0.1)(x)\n",
        "\t\tself.feature_extractor = Model(input_image, x)\n",
        "\tdef normalize(self, image):\n",
        "\t\treturn image / 255.\n",
        "\n",
        "def parse_annotation(ann_dir, img_dir, labels=[]):\n",
        "\tall_imgs = []\n",
        "\tseen_labels = {}\n",
        "\tfor ann in sorted(os.listdir(ann_dir)):\n",
        "\t\timg = {'object':[]}\n",
        "\t\ttree = ET.parse(ann_dir + ann)\n",
        "\t\tfor elem in tree.iter():\n",
        "\t\t\tif 'filename' in elem.tag:\n",
        "\t\t\t\timg['filename'] = img_dir + elem.text\n",
        "\t\t\tif 'width' in elem.tag:\n",
        "\t\t\t\timg['width'] = int(elem.text)\n",
        "\t\t\tif 'height' in elem.tag:\n",
        "\t\t\t\timg['height'] = int(elem.text)\n",
        "\t\t\tif 'object' in elem.tag or 'part' in elem.tag:\n",
        "\t\t\t\tobj = {}\n",
        "\t\t\t\tfor attr in list(elem):\n",
        "\t\t\t\t\tif 'name' in attr.tag:\n",
        "\t\t\t\t\t\tobj['name'] = attr.text\n",
        "\t\t\t\t\t\tif obj['name'] in seen_labels:\n",
        "\t\t\t\t\t\t\tseen_labels[obj['name']] += 1\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tseen_labels[obj['name']] = 1\n",
        "\t\t\t\t\t\tif len(labels) > 0 and obj['name'] not in labels:\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\timg['object'] += [obj]\n",
        "\t\t\t\t\tif 'bndbox' in attr.tag:\n",
        "\t\t\t\t\t\tfor dim in list(attr):\n",
        "\t\t\t\t\t\t\tif 'xmin' in dim.tag:\n",
        "\t\t\t\t\t\t\t\tobj['xmin'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\tif 'ymin' in dim.tag:\n",
        "\t\t\t\t\t\t\t\tobj['ymin'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\tif 'xmax' in dim.tag:\n",
        "\t\t\t\t\t\t\t\tobj['xmax'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\tif 'ymax' in dim.tag:\n",
        "\t\t\t\t\t\t\t\tobj['ymax'] = int(round(float(dim.text)))\n",
        "\t\tif len(img['object']) > 0:\n",
        "\t\t\tall_imgs += [img]\n",
        "\treturn all_imgs, seen_labels\n",
        "\n",
        "class BatchGenerator(Sequence):\n",
        "\tdef __init__(self, images, config, shuffle=True, jitter=True, norm=None):\n",
        "\t\tself.generator = None\n",
        "\t\tself.images = images\n",
        "\t\tself.config = config\n",
        "\t\tself.shuffle = shuffle\n",
        "\t\tself.jitter = jitter\n",
        "\t\tself.norm = norm\n",
        "\t\tself.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i],\n",
        "\t\t\t\t\t\t\t\t\tconfig['ANCHORS'][2*i+1])\\\n",
        "\t\t\t\t\t\tfor i in range(int(len(config['ANCHORS'])//2))]\n",
        "\t\tsometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\t\tself.aug_pipe = iaa.Sequential([sometimes(iaa.Affine()),\n",
        "\t\t\t\tiaa.SomeOf((0, 5),\n",
        "\t\t\t\t\t\t[iaa.OneOf([iaa.GaussianBlur((0, 3.0)),\n",
        "\t\t\t\t\t\tiaa.AverageBlur(k=(2, 7)),\n",
        "\t\t\t\t\t\tiaa.MedianBlur(k=(3, 11)),]),\n",
        "\t\t\t\t\t\tiaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
        "\t\t\t\t\t\tiaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tper_channel=0.5),\n",
        "\t\t\t\t\t\tiaa.OneOf([iaa.Dropout((0.01, 0.1), per_channel=0.5),]),\n",
        "\t\t\t\t\t\tiaa.Add((-10, 10), per_channel=0.5),\n",
        "\t\t\t\t\t\tiaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
        "\t\t\t\t\t\tiaa.ContrastNormalization((0.5, 2.0),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tper_channel=0.5),],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\trandom_order=True)],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\trandom_order=True)\n",
        "\t\tif shuffle: np.random.shuffle(self.images)\n",
        "\tdef __len__(self):\n",
        "\t\treturn int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))\n",
        "\tdef num_classes(self):\n",
        "\t\treturn len(self.config['LABELS'])\n",
        "\tdef size(self):\n",
        "\t\treturn len(self.images)\n",
        "\tdef load_annotation(self, i):\n",
        "\t\tannots = []\n",
        "\t\tfor obj in self.images[i]['object']:\n",
        "\t\t\tannot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'],\n",
        "\t\t\t\t\tself.config['LABELS'].index(obj['name'])]\n",
        "\t\t\tannots += [annot]\n",
        "\t\tif len(annots) == 0: annots = [[]]\n",
        "\t\treturn np.array(annots)\n",
        "\tdef load_image(self, i):\n",
        "\t\treturn cv2.imread(self.images[i]['filename'])\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tl_bound = idx*self.config['BATCH_SIZE']\n",
        "\t\tr_bound = (idx+1)*self.config['BATCH_SIZE']\n",
        "\t\tif r_bound > len(self.images):\n",
        "\t\t\tr_bound = len(self.images)\n",
        "\t\t\tl_bound = r_bound - self.config['BATCH_SIZE']\n",
        "\t\tinstance_count = 0\n",
        "\t\tx_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'],\n",
        "\t\t\t\t\t\t\tself.config['IMAGE_W'], 3))\n",
        "\t\tb_batch = np.zeros((r_bound - l_bound, 1, 1, 1,\n",
        "\t\t\t\t\t\t\tself.config['TRUE_BOX_BUFFER'], 4))\n",
        "\t\ty_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],\n",
        "\t\t\t\t\t\t\tself.config['GRID_W'], self.config['BOX'],\n",
        "\t\t\t\t\t\t\t4+1+len(self.config['LABELS'])))\n",
        "\t\tfor train_instance in self.images[l_bound:r_bound]:\n",
        "\t\t\timg, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
        "\t\t\ttrue_box_index = 0\n",
        "\t\t\tfor obj in all_objs:\n",
        "\t\t\t\tif obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']\\\n",
        "\t\t\t\t\t\t\t\t\tand obj['name'] in self.config['LABELS']:\n",
        "\t\t\t\t\tcenter_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "\t\t\t\t\tcenter_x = center_x / (float(self.config['IMAGE_W']) /\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tself.config['GRID_W'])\n",
        "\t\t\t\t\tcenter_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "\t\t\t\t\tcenter_y = center_y / (float(self.config['IMAGE_H']) /\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tself.config['GRID_H'])\n",
        "\t\t\t\t\tgrid_x = int(np.floor(center_x))\n",
        "\t\t\t\t\tgrid_y = int(np.floor(center_y))\n",
        "\t\t\t\t\tif grid_x < self.config['GRID_W'] and\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tgrid_y < self.config['GRID_H']:\n",
        "\t\t\t\t\t\tobj_indx = self.config['LABELS'].index(obj['name'])\n",
        "\t\t\t\t\t\tcenter_w = (obj['xmax'] - obj['xmin']) /\\\n",
        "\t\t\t\t\t\t(float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
        "\t\t\t\t\t\tcenter_h = (obj['ymax'] - obj['ymin']) /\\\n",
        "\t\t\t\t\t\t(float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
        "\t\t\t\t\t\tbox = [center_x, center_y, center_w, center_h]\n",
        "\t\t\t\t\t\tbest_anchor = -1\n",
        "\t\t\t\t\t\tmax_iou = -1\n",
        "\t\t\t\t\t\tshifted_box = BoundBox(0, 0, center_w, center_h)\n",
        "\t\t\t\t\t\tfor i in range(len(self.anchors)):\n",
        "\t\t\t\t\t\t\tanchor = self.anchors[i]\n",
        "\t\t\t\t\t\t\tiou = bbox_iou(shifted_box, anchor)\n",
        "\t\t\t\t\t\t\tif max_iou < iou:\n",
        "\t\t\t\t\t\t\t\tbest_anchor = i\n",
        "\t\t\t\t\t\t\t\tmax_iou = iou\n",
        "\t\t\t\t\t\ty_batch[instance_count,\n",
        "\t\t\t\t\t\t\t\tgrid_y, grid_x, best_anchor, 0:4] = box\n",
        "\t\t\t\t\t\ty_batch[instance_count,\n",
        "\t\t\t\t\t\t\t\tgrid_y, grid_x, best_anchor, 4\t] = 1.\n",
        "\t\t\t\t\t\ty_batch[instance_count,\n",
        "\t\t\t\t\t\t\t\tgrid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
        "\t\t\t\t\t\tb_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
        "\t\t\t\t\t\ttrue_box_index += 1\n",
        "\t\t\t\t\t\ttrue_box_index = true_box_index %\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tself.config['TRUE_BOX_BUFFER']\n",
        "\t\t\tif self.norm != None:\n",
        "\t\t\t\tx_batch[instance_count] = self.norm(img)\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor obj in all_objs:\n",
        "\t\t\t\t\tif obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\n",
        "\t\t\t\t\t\tcv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']),\n",
        "\t\t\t\t\t\t\t\t\t(obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
        "\t\t\t\t\t\tcv2.putText(img[:,:,::-1], obj['name'], (obj['xmin']+2,\n",
        "\t\t\t\t\t\t\t\t\tobj['ymin']+12), 0, 1.2e-3 * img.shape[0],\n",
        "\t\t\t\t\t\t\t\t\t(0,255,0), 2)\n",
        "\t\t\t\tx_batch[instance_count] = img\n",
        "\t\t\tinstance_count += 1\n",
        "\t\treturn [x_batch, b_batch], y_batch\n",
        "\tdef on_epoch_end(self):\n",
        "\t\tif self.shuffle: np.random.shuffle(self.images)\n",
        "\tdef aug_image(self, train_instance, jitter):\n",
        "\t\timage_name = train_instance['filename']\n",
        "\t\timage = cv2.imread(image_name)\n",
        "\t\tif image is None: print('Cannot find ', image_name)\n",
        "\t\th, w, c = image.shape\n",
        "\t\tall_objs = copy.deepcopy(train_instance['object'])\n",
        "\t\tif jitter:\n",
        "\t\t\tscale = np.random.uniform() / 10. + 1.\n",
        "\t\t\timage = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
        "\t\t\tmax_offx = (scale-1.) * w\n",
        "\t\t\tmax_offy = (scale-1.) * h\n",
        "\t\t\toffx = int(np.random.uniform() * max_offx)\n",
        "\t\t\toffy = int(np.random.uniform() * max_offy)\n",
        "\t\t\timage = image[offy : (offy + h), offx : (offx + w)]\n",
        "\t\t\tflip = np.random.binomial(1, .5)\n",
        "\t\t\tif flip > 0.5: image = cv2.flip(image, 1)\n",
        "\t\t\timage = self.aug_pipe.augment_image(image)\n",
        "\t\timage = cv2.resize(image,\n",
        "\t\t\t\t\t\t(self.config['IMAGE_H'], self.config['IMAGE_W']))\n",
        "\t\timage = image[:,:,::-1]\n",
        "\t\tfor obj in all_objs:\n",
        "\t\t\tfor attr in ['xmin', 'xmax']:\n",
        "\t\t\t\tif jitter: obj[attr] = int(obj[attr] * scale - offx)\n",
        "\t\t\t\tobj[attr] = int(obj[attr] * float(self.config['IMAGE_W']) / w)\n",
        "\t\t\t\tobj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\n",
        "\t\t\tfor attr in ['ymin', 'ymax']:\n",
        "\t\t\t\tif jitter: obj[attr] = int(obj[attr] * scale - offy)\n",
        "\t\t\t\tobj[attr] = int(obj[attr] * float(self.config['IMAGE_H']) / h)\n",
        "\t\t\t\tobj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\n",
        "\t\t\tif jitter and flip > 0.5:\n",
        "\t\t\t\txmin = obj['xmin']\n",
        "\t\t\t\tobj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\n",
        "\t\t\t\tobj['xmax'] = self.config['IMAGE_W'] - xmin\n",
        "\t\treturn image, all_objs\n",
        "\n",
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.c = c\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        "\t\treturn self.label\n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        "\t\treturn self.score\n",
        "\n",
        "class WeightReader:\n",
        "\tdef __init__(self, weight_file):\n",
        "\t\tself.offset = 4\n",
        "\t\tself.all_weights = np.fromfile(weight_file, dtype='float32')\n",
        "\tdef read_bytes(self, size):\n",
        "\t\tself.offset = self.offset + size\n",
        "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
        "\tdef reset(self):\n",
        "\t\tself.offset = 4\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax],\n",
        "\t\t\t\t\t\t\t\t\t[box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax],\n",
        "\t\t\t\t\t\t\t\t\t[box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        "\n",
        "def draw_boxes(image, boxes, labels):\n",
        "\timage_h, image_w, _ = image.shape\n",
        "\tfor box in boxes:\n",
        "\t\txmin = int(box.xmin*image_w)\n",
        "\t\tymin = int(box.ymin*image_h)\n",
        "\t\txmax = int(box.xmax*image_w)\n",
        "\t\tymax = int(box.ymax*image_h)\n",
        "\t\tcv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
        "\t\tcv2.putText(image, labels[box.get_label()] + ' ' + str(box.get_score()),\n",
        "\t\t\t\t\t(xmin, ymin - 13), cv2.FONT_HERSHEY_SIMPLEX, 1e-3 * image_h,\n",
        "\t\t\t\t\t(0,255,0), 2)\n",
        "\treturn image\n",
        "\n",
        "def decode_netout(netout, anchors, nb_class,\n",
        "\t\t\t\t\tobj_threshold=0.3, nms_threshold=0.3):\n",
        "\tgrid_h, grid_w, nb_box = netout.shape[:3]\n",
        "\tboxes = []\n",
        "\tnetout[..., 4] = _sigmoid(netout[..., 4])\n",
        "\tnetout[..., 5:] = netout[..., 4][..., np.newaxis]*_softmax(netout[..., 5:])\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
        "\tfor row in range(grid_h):\n",
        "\t\tfor col in range(grid_w):\n",
        "\t\t\tfor b in range(nb_box):\n",
        "\t\t\t\tclasses = netout[row,col,b,5:]\n",
        "\t\t\t\tif np.sum(classes) > 0:\n",
        "\t\t\t\t\tx, y, w, h = netout[row,col,b,:4]\n",
        "\t\t\t\t\tx = (col + _sigmoid(x)) / grid_w\n",
        "\t\t\t\t\ty = (row + _sigmoid(y)) / grid_h\n",
        "\t\t\t\t\tw = anchors[2 * b + 0] * np.exp(w) / grid_w\n",
        "\t\t\t\t\th = anchors[2 * b + 1] * np.exp(h) / grid_h\n",
        "\t\t\t\t\tconfidence = netout[row,col,b,4]\n",
        "\t\t\t\t\tbox = BoundBox(x-w/2,y-h/2,x+w/2,y+h/2,confidence,classes)\n",
        "\t\t\t\t\tboxes.append(box)\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = list(reversed(np.argsort([box.classes[c]\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfor box in boxes])))\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j])>=nms_threshold:\n",
        "\t\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        "\tboxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
        "\treturn boxes\n",
        "\n",
        "def compute_overlap(a, b):\n",
        "\tarea = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
        "\tiw = np.minimum(np.expand_dims(a[:, 2], axis=1),\n",
        "\t\t\t\t\tb[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
        "\tih = np.minimum(np.expand_dims(a[:, 3], axis=1),\n",
        "\t\t\t\t\tb[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
        "\tiw = np.maximum(iw, 0)\n",
        "\tih = np.maximum(ih, 0)\n",
        "\tua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]),\n",
        "\t\t\t\t\t\taxis=1) + area - iw * ih\n",
        "\tua = np.maximum(ua, np.finfo(float).eps)\n",
        "\tintersection = iw * ih\n",
        "\treturn intersection / ua\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "\tmrec = np.concatenate(([0.], recall, [1.]))\n",
        "\tmpre = np.concatenate(([0.], precision, [0.]))\n",
        "\tfor i in range(mpre.size - 1, 0, -1):\n",
        "\t\tmpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\ti = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\tap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "\treturn ap\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3\n",
        "\n",
        "def _sigmoid(x):\n",
        "\treturn 1. / (1. + np.exp(-x))\n",
        "\n",
        "def _softmax(x, axis=-1, t=-100.):\n",
        "\tx = x - np.max(x)\n",
        "\tif np.min(x) < t:\n",
        "\t\tx = x/np.min(x)*t\n",
        "\te_x = np.exp(x)\n",
        "\treturn e_x / e_x.sum(axis, keepdims=True)\n",
        "\n",
        "class YOLO(object):\n",
        "\tdef __init__(self, input_size, labels, max_box_per_image, anchors):\n",
        "\t\tself.input_size = input_size\n",
        "\t\tself.labels = list(labels)\n",
        "\t\tself.nb_class = len(self.labels)\n",
        "\t\tself.nb_box = len(anchors)//2\n",
        "\t\tself.class_wt = np.ones(self.nb_class, dtype='float32')\n",
        "\t\tself.anchors = anchors\n",
        "\t\tself.max_box_per_image = max_box_per_image\n",
        "\t\tinput_image = Input(shape=(self.input_size, self.input_size, 3))\n",
        "\t\tself.true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))\n",
        "\t\tself.feature_extractor = FullYoloFeature(self.input_size)\n",
        "\t\tprint(self.feature_extractor.get_output_shape())\n",
        "\t\tself.grid_h, self.grid_w = self.feature_extractor.get_output_shape()\n",
        "\t\tfeatures = self.feature_extractor.extract(input_image)\n",
        "\t\toutput = Conv2D(self.nb_box * (4 + 1 + self.nb_class),\n",
        "\t\t\t\t\t\t(1,1), strides=(1,1),\n",
        "\t\t\t\t\t\tpadding='same',\n",
        "\t\t\t\t\t\tname='DetectionLayer',\n",
        "\t\t\t\t\t\tkernel_initializer='lecun_normal')(features)\n",
        "\t\toutput = Reshape((self.grid_h, self.grid_w, self.nb_box,\n",
        "\t\t\t\t\t\t4 + 1 + self.nb_class))(output)\n",
        "\t\toutput = Lambda(lambda args: args[0])([output, self.true_boxes])\n",
        "\t\tself.model = Model([input_image, self.true_boxes], output)\n",
        "\t\tlayer = self.model.layers[-4]\n",
        "\t\tweights = layer.get_weights()\n",
        "\t\tnew_kernel = np.random.normal(size=weights[0].shape)/\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t(self.grid_h*self.grid_w)\n",
        "\t\tnew_bias = np.random.normal(size=weights[1].shape)/\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t(self.grid_h*self.grid_w)\n",
        "\t\tlayer.set_weights([new_kernel, new_bias])\n",
        "\t\tself.model.summary()\n",
        "\tdef custom_loss(self, y_true, y_pred):\n",
        "\t\tmask_shape = tf.shape(y_true)[:4]\n",
        "\t\tcell_x = tf.to_float(tf.reshape(tf.tile(tf.range(self.grid_w),\n",
        "\t\t\t\t\t\t\t\t\t\t[self.grid_h]),\n",
        "\t\t\t\t\t\t\t\t\t\t(1, self.grid_h, self.grid_w, 1, 1)))\n",
        "\t\tcell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\t\tcell_grid = tf.tile(tf.concat([cell_x,cell_y], -1),\n",
        "\t\t\t\t\t\t\t\t\t\t[self.batch_size, 1, 1, self.nb_box, 1])\n",
        "\t\tcoord_mask = tf.zeros(mask_shape)\n",
        "\t\tconf_mask = tf.zeros(mask_shape)\n",
        "\t\tclass_mask = tf.zeros(mask_shape)\n",
        "\t\tseen = tf.Variable(0.)\n",
        "\t\ttotal_recall = tf.Variable(0.)\n",
        "\t\tpred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "\t\tpred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(self.anchors,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[1,1,1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.nb_box,2])\n",
        "\t\tpred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "\t\tpred_box_class = y_pred[..., 5:]\n",
        "\t\ttrue_box_xy = y_true[..., 0:2]\n",
        "\t\ttrue_box_wh = y_true[..., 2:4]\n",
        "\t\ttrue_wh_half = true_box_wh / 2.\n",
        "\t\ttrue_mins = true_box_xy - true_wh_half\n",
        "\t\ttrue_maxes = true_box_xy + true_wh_half\n",
        "\t\tpred_wh_half = pred_box_wh / 2.\n",
        "\t\tpred_mins = pred_box_xy - pred_wh_half\n",
        "\t\tpred_maxes = pred_box_xy + pred_wh_half\n",
        "\t\tintersect_mins = tf.maximum(pred_mins,  true_mins)\n",
        "\t\tintersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "\t\tintersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "\t\tintersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\t\ttrue_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "\t\tpred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\t\tunion_areas = pred_areas + true_areas - intersect_areas\n",
        "\t\tiou_scores = tf.truediv(intersect_areas, union_areas)\n",
        "\t\ttrue_box_conf = iou_scores * y_true[..., 4]\n",
        "\t\ttrue_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "\t\tcoord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * self.coord_scale\n",
        "\t\ttrue_xy = self.true_boxes[..., 0:2]\n",
        "\t\ttrue_wh = self.true_boxes[..., 2:4]\n",
        "\t\ttrue_wh_half = true_wh / 2.\n",
        "\t\ttrue_mins = true_xy - true_wh_half\n",
        "\t\ttrue_maxes = true_xy + true_wh_half\n",
        "\t\tpred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "\t\tpred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "\t\tpred_wh_half = pred_wh / 2.\n",
        "\t\tpred_mins = pred_xy - pred_wh_half\n",
        "\t\tpred_maxes = pred_xy + pred_wh_half\n",
        "\t\tintersect_mins = tf.maximum(pred_mins,  true_mins)\n",
        "\t\tintersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "\t\tintersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "\t\tintersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\t\ttrue_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "\t\tpred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\t\tunion_areas = pred_areas + true_areas - intersect_areas\n",
        "\t\tiou_scores = tf.truediv(intersect_areas, union_areas)\n",
        "\t\tbest_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "\t\tconf_mask = conf_mask + tf.to_float(best_ious < 0.6) *\\\n",
        "\t\t\t\t\t\t\t\t\t(1 - y_true[..., 4]) * self.no_object_scale\n",
        "\t\tconf_mask = conf_mask + y_true[..., 4] * self.object_scale\n",
        "\t\tclass_mask = y_true[..., 4] *\\\n",
        "\t\t\t\t\ttf.gather(self.class_wt, true_box_class) * self.class_scale\n",
        "\t\tno_boxes_mask = tf.to_float(coord_mask < self.coord_scale/2.)\n",
        "\t\tseen = tf.assign_add(seen, 1.)\n",
        "\t\ttrue_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.warmup_batches+1),\n",
        "\t\t\t\t\t\t\tlambda: [true_box_xy + (0.5 + cell_grid)\\\n",
        "\t\t\t\t\t\t\t\t\t* no_boxes_mask,\\\n",
        "\t\t\t\t\t\t\t\t\ttrue_box_wh + tf.ones_like(true_box_wh) *\\\n",
        "\t\t\t\t\t\t\t\t\tnp.reshape(self.anchors,\\\n",
        "\t\t\t\t\t\t\t\t\t[1,1,1,self.nb_box,2]) * \\\n",
        "\t\t\t\t\t\t\t\t\tno_boxes_mask,\n",
        "\t\t\t\t\t\t\t\t\ttf.ones_like(coord_mask)],\n",
        "\t\t\t\t\t\t\tlambda: [true_box_xy,\n",
        "\t\t\t\t\t\t\t\t\ttrue_box_wh,\n",
        "\t\t\t\t\t\t\t\t\tcoord_mask])\n",
        "\t\tnb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "\t\tnb_conf_box = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "\t\tnb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "\t\tloss_xy = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)\\\n",
        "\t\t\t\t\t\t\t\t\t* coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "\t\tloss_wh = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)\\\n",
        "\t\t\t\t\t\t\t\t\t* coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "\t\tloss_conf = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf)\\\n",
        "\t\t\t\t\t\t\t\t\t* conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "\t\tloss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=\\\n",
        "\t\t\t\t\t\t\t\t\t\ttrue_box_class, logits=pred_box_class)\n",
        "\t\tloss_class = tf.reduce_sum(loss_class * class_mask) /\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t(nb_class_box + 1e-6)\n",
        "\t\tloss = tf.cond(tf.less(seen, self.warmup_batches+1),\n",
        "\t\t\t\t\tlambda: loss_xy + loss_wh + loss_conf + loss_class + 10,\n",
        "\t\t\t\t\tlambda: loss_xy + loss_wh + loss_conf + loss_class)\n",
        "\t\tif self.debug:\n",
        "\t\t\tnb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "\t\t\tnb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5)\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t* tf.to_float(pred_box_conf > 0.3))\n",
        "\t\t\tcurrent_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "\t\t\ttotal_recall = tf.assign_add(total_recall, current_recall)\n",
        "\t\t\tloss = tf.Print(loss, [loss_xy], message='Loss XY \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\tloss = tf.Print(loss, [loss_wh], message='Loss WH \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\tloss = tf.Print(loss, [loss_conf], message='Loss Conf \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\tloss = tf.Print(loss, [loss_class], message='Loss Class \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\tloss = tf.Print(loss, [loss], message='Total Loss \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\tloss = tf.Print(loss, [current_recall], message='Current Recall \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\tloss = tf.Print(loss, [total_recall/seen], message=\\\n",
        "\t\t\t\t\t\t\t'Average Recall \\t',\n",
        "\t\t\t\t\t\t\tsummarize=1000)\n",
        "\t\t\treturn loss\n",
        "\tdef load_weights(self, weight_path):\n",
        "\t\tself.model.load_weights(weight_path)\n",
        "\tdef train(self, train_imgs,\n",
        "\t\t\t\t\tvalid_imgs,\n",
        "\t\t\t\t\ttrain_times,\n",
        "\t\t\t\t\tvalid_times,\n",
        "\t\t\t\t\tnb_epochs,\n",
        "\t\t\t\t\tlearning_rate,\n",
        "\t\t\t\t\tbatch_size,\n",
        "\t\t\t\t\twarmup_epochs,\n",
        "\t\t\t\t\tobject_scale,\n",
        "\t\t\t\t\tno_object_scale,\n",
        "\t\t\t\t\tcoord_scale,\n",
        "\t\t\t\t\tclass_scale,\n",
        "\t\t\t\t\tsaved_weights_name='best_weights.h5',\n",
        "\t\t\t\t\tdebug=False):\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.object_scale = object_scale\n",
        "\t\tself.no_object_scale = no_object_scale\n",
        "\t\tself.coord_scale = coord_scale\n",
        "\t\tself.class_scale = class_scale\n",
        "\t\tself.debug = debug\n",
        "\t\tgenerator_config = {\n",
        "\t\t\t'IMAGE_H': self.input_size,\n",
        "\t\t\t'IMAGE_W': self.input_size,\n",
        "\t\t\t'GRID_H': self.grid_h,\n",
        "\t\t\t'GRID_W': self.grid_w,\n",
        "\t\t\t'BOX': self.nb_box,\n",
        "\t\t\t'LABELS': self.labels,\n",
        "\t\t\t'CLASS': len(self.labels),\n",
        "\t\t\t'ANCHORS': self.anchors,\n",
        "\t\t\t'BATCH_SIZE': self.batch_size,\n",
        "\t\t\t'TRUE_BOX_BUFFER': self.max_box_per_image,}\n",
        "\t\ttrain_generator = BatchGenerator(train_imgs,\n",
        "\t\t\t\t\t\t\t\t\t\tgenerator_config,\n",
        "\t\t\t\t\t\t\t\t\t\tnorm=self.feature_extractor.normalize)\n",
        "\t\tvalid_generator = BatchGenerator(valid_imgs,\n",
        "\t\t\t\t\t\t\t\t\t\tgenerator_config,\n",
        "\t\t\t\t\t\t\t\t\t\tnorm=self.feature_extractor.normalize,\n",
        "\t\t\t\t\t\t\t\t\t\tjitter=False)\n",
        "\t\tself.warmup_batches  = warmup_epochs *\\\n",
        "\t\t(train_times*len(train_generator) + valid_times*len(valid_generator))\n",
        "\t\toptimizer = Adam(lr=learning_rate,\n",
        "\t\t\t\t\t\tbeta_1=0.9,\n",
        "\t\t\t\t\t\tbeta_2=0.999,\n",
        "\t\t\t\t\t\tepsilon=1e-08,\n",
        "\t\t\t\t\t\tdecay=0.0)\n",
        "\t\tself.model.compile(loss=self.custom_loss, optimizer=optimizer)\n",
        "\t\tearly_stop = EarlyStopping(monitor='val_loss',\n",
        "\t\t\t\t\t\t\t\t\tmin_delta=0.001,\n",
        "\t\t\t\t\t\t\t\t\tpatience=10,\n",
        "\t\t\t\t\t\t\t\t\tmode='min',\n",
        "\t\t\t\t\t\t\t\t\tverbose=1)\n",
        "\t\tcheckpoint = ModelCheckpoint(saved_weights_name,\n",
        "\t\t\t\t\t\t\t\t\tmonitor='val_loss',\n",
        "\t\t\t\t\t\t\t\t\tverbose=1,\n",
        "\t\t\t\t\t\t\t\t\tsave_best_only=True,\n",
        "\t\t\t\t\t\t\t\t\tmode='min',\n",
        "\t\t\t\t\t\t\t\t\tperiod=1)\n",
        "\t\ttensorboard = TensorBoard(log_dir=os.path.expanduser('./logs/'),\n",
        "\t\t\t\t\t\t\t\t\thistogram_freq=0,\n",
        "\t\t\t\t\t\t\t\t\twrite_graph=True,\n",
        "\t\t\t\t\t\t\t\t\twrite_images=False)\n",
        "\t\tself.model.fit_generator(generator = train_generator,\n",
        "\t\t\t\t\t\t\t\tsteps_per_epoch = len(train_generator)\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t* train_times,\n",
        "\t\t\t\t\t\t\t\tepochs = warmup_epochs + nb_epochs,\n",
        "\t\t\t\t\t\t\t\tverbose = 1,\n",
        "\t\t\t\t\t\t\t\tvalidation_data = valid_generator,\n",
        "\t\t\t\t\t\t\t\tvalidation_steps = len(valid_generator)\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t* valid_times,\n",
        "\t\t\t\t\t\t\t\tcallbacks = [early_stop,checkpoint,tensorboard],\n",
        "\t\t\t\t\t\t\t\tworkers = 3,\n",
        "\t\t\t\t\t\t\t\tmax_queue_size = 8)\n",
        "\t\taverage_precisions = self.evaluate(valid_generator)\n",
        "\t\tfor label, average_precision in average_precisions.items():\n",
        "\t\t\tprint(self.labels[label], '{:.4f}'.format(average_precision))\n",
        "\t\tprint('mAP: {:.4f}'.format(sum(average_precisions.values()) /\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tlen(average_precisions)))\n",
        "\tdef evaluate(self,\n",
        "\t\t\t\tgenerator,\n",
        "\t\t\t\tiou_threshold=0.3,\n",
        "\t\t\t\tscore_threshold=0.3,\n",
        "\t\t\t\tmax_detections=100,\n",
        "\t\t\t\tsave_path=None):\n",
        "\t\tall_detections = [[None for i in range(generator.num_classes())] for\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tj in range(generator.size())]\n",
        "\t\tall_annotations = [[None for i in range(generator.num_classes())] for\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tj in range(generator.size())]\n",
        "\t\tfor i in range(generator.size()):\n",
        "\t\t\traw_image = generator.load_image(i)\n",
        "\t\t\traw_height, raw_width, raw_channels = raw_image.shape\n",
        "\t\t\tpred_boxes = self.predict(raw_image)\n",
        "\t\t\tscore = np.array([box.score for box in pred_boxes])\n",
        "\t\t\tpred_labels = np.array([box.label for box in pred_boxes])\n",
        "\t\t\tif len(pred_boxes) > 0:\n",
        "\t\t\t\tpred_boxes = np.array([[box.xmin*raw_width,\n",
        "\t\t\t\t\t\t\t\t\t\tbox.ymin*raw_height,\n",
        "\t\t\t\t\t\t\t\t\t\tbox.xmax*raw_width,\n",
        "\t\t\t\t\t\t\t\t\t\tbox.ymax*raw_height,\n",
        "\t\t\t\t\t\t\t\t\t\tbox.score] for box in pred_boxes])\n",
        "\t\t\telse:\n",
        "\t\t\t\tpred_boxes = np.array([[]])\n",
        "\t\t\tscore_sort = np.argsort(-score)\n",
        "\t\t\tpred_labels = pred_labels[score_sort]\n",
        "\t\t\tpred_boxes = pred_boxes[score_sort]\n",
        "\t\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\t\tall_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
        "\t\t\tannotations = generator.load_annotation(i)\n",
        "\t\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\t\tall_annotations[i][label] = annotations[annotations[:, 4] ==\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlabel, :4].copy()\n",
        "\t\taverage_precisions = {}\n",
        "\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\tfalse_positives = np.zeros((0,))\n",
        "\t\t\ttrue_positives = np.zeros((0,))\n",
        "\t\t\tscores = np.zeros((0,))\n",
        "\t\t\tnum_annotations = 0.0\n",
        "\t\t\tfor i in range(generator.size()):\n",
        "\t\t\t\tdetections = all_detections[i][label]\n",
        "\t\t\t\tannotations = all_annotations[i][label]\n",
        "\t\t\t\tnum_annotations += annotations.shape[0]\n",
        "\t\t\t\tdetected_annotations = []\n",
        "\t\t\t\tfor d in detections:\n",
        "\t\t\t\t\tscores = np.append(scores, d[4])\n",
        "\t\t\t\t\tif annotations.shape[0] == 0:\n",
        "\t\t\t\t\t\tfalse_positives = np.append(false_positives, 1)\n",
        "\t\t\t\t\t\ttrue_positives = np.append(true_positives, 0)\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\toverlaps = compute_overlap(np.expand_dims(d, axis=0),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tannotations)\n",
        "\t\t\t\t\tassigned_annotation = np.argmax(overlaps, axis=1)\n",
        "\t\t\t\t\tmax_overlap = overlaps[0, assigned_annotation]\n",
        "\t\t\t\t\tif max_overlap >= iou_threshold\\\n",
        "\t\t\t\t\t\t\tand assigned_annotation not in detected_annotations:\n",
        "\t\t\t\t\t\tfalse_positives = np.append(false_positives, 0)\n",
        "\t\t\t\t\t\ttrue_positives = np.append(true_positives, 1)\n",
        "\t\t\t\t\t\tdetected_annotations.append(assigned_annotation)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tfalse_positives = np.append(false_positives, 1)\n",
        "\t\t\t\t\t\ttrue_positives = np.append(true_positives, 0)\n",
        "\t\t\tif num_annotations == 0:\n",
        "\t\t\t\taverage_precisions[label] = 0\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tindices = np.argsort(-scores)\n",
        "\t\t\tfalse_positives = false_positives[indices]\n",
        "\t\t\ttrue_positives = true_positives[indices]\n",
        "\t\t\tfalse_positives = np.cumsum(false_positives)\n",
        "\t\t\ttrue_positives = np.cumsum(true_positives)\n",
        "\t\t\trecall = true_positives / num_annotations\n",
        "\t\t\tprecision = true_positives / np.maximum(true_positives +\\\n",
        "\t\t\t\t\t\t\t\t\tfalse_positives, np.finfo(np.float64).eps)\n",
        "\t\t\taverage_precision = compute_ap(recall, precision)\n",
        "\t\t\taverage_precisions[label] = average_precision\n",
        "\t\treturn average_precisions\n",
        "\tdef predict(self, image):\n",
        "\t\timage_h, image_w, _ = image.shape\n",
        "\t\timage = cv2.resize(image, (self.input_size, self.input_size))\n",
        "\t\timage = self.feature_extractor.normalize(image)\n",
        "\t\tinput_image = image[:,:,::-1]\n",
        "\t\tinput_image = np.expand_dims(input_image, 0)\n",
        "\t\tdummy_array = np.zeros((1,1,1,1,self.max_box_per_image,4))\n",
        "\t\tnetout = self.model.predict([input_image, dummy_array])[0]\n",
        "\t\tboxes = decode_netout(netout, self.anchors, self.nb_class)\n",
        "\t\treturn boxes\n",
        "\n",
        "def train():\n",
        "\ttrain_imgs, train_labels = parse_annotation(config['train']\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t['train_annot_folder'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tconfig['train']\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t['train_image_folder'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tconfig['model']\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t['labels'])\n",
        "\tif os.path.exists(config['valid']['valid_annot_folder']):\n",
        "\t\tvalid_imgs, valid_labels = parse_annotation(config['valid']\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t['valid_annot_folder'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tconfig['valid']\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t['valid_image_folder'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tconfig['model']\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t['labels'])\n",
        "\telse:\n",
        "\t\ttrain_valid_split = int(0.8*len(train_imgs))\n",
        "\t\tnp.random.shuffle(train_imgs)\n",
        "\t\tvalid_imgs = train_imgs[train_valid_split:]\n",
        "\t\ttrain_imgs = train_imgs[:train_valid_split]\n",
        "\tif len(config['model']['labels']) > 0:\n",
        "\t\toverlap_labels = set(config['model']['labels']).intersection(set(\\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttrain_labels.keys()))\n",
        "\t\tprint('Seen labels:\\t', train_labels)\n",
        "\t\tprint('Given labels:\\t', config['model']['labels'])\n",
        "\t\tprint('Overlap labels:\\t', overlap_labels)\n",
        "\t\tif len(overlap_labels) < len(config['model']['labels']):\n",
        "\t\t\tprint('Some labels have no annotations! Revise the list of labels')\n",
        "\t\t\treturn\n",
        "\telse:\n",
        "\t\tprint('No labels are provided. Train on all seen labels.')\n",
        "\t\tconfig['model']['labels'] = train_labels.keys()\n",
        "\tyolo = YOLO(input_size = config['model']['input_size'],\n",
        "\t\t\t\tlabels = config['model']['labels'],\n",
        "\t\t\t\tmax_box_per_image = config['model']['max_box_per_image'],\n",
        "\t\t\t\tanchors = config['model']['anchors'])\n",
        "\tyolo.train(train_imgs = train_imgs,\n",
        "\t\t\t\tvalid_imgs = valid_imgs,\n",
        "\t\t\t\ttrain_times = config['train']['train_times'],\n",
        "\t\t\t\tvalid_times = config['valid']['valid_times'],\n",
        "\t\t\t\tnb_epochs = config['train']['nb_epochs'],\n",
        "\t\t\t\tlearning_rate = config['train']['learning_rate'],\n",
        "\t\t\t\tbatch_size = config['train']['batch_size'],\n",
        "\t\t\t\twarmup_epochs = config['train']['warmup_epochs'],\n",
        "\t\t\t\tobject_scale = config['train']['object_scale'],\n",
        "\t\t\t\tno_object_scale = config['train']['no_object_scale'],\n",
        "\t\t\t\tcoord_scale = config['train']['coord_scale'],\n",
        "\t\t\t\tclass_scale = config['train']['class_scale'],\n",
        "\t\t\t\tsaved_weights_name = config['train']['saved_weights_name'],\n",
        "\t\t\t\tdebug = config['train']['debug'])\n",
        "\n",
        "def predict(h5weights, TheImage):\n",
        "\tweights_path = h5weights\n",
        "\timage_path = TheImage\n",
        "\tyolo = YOLO(input_size = config['model']['input_size'],\n",
        "\t\t\t\tlabels = config['model']['labels'],\n",
        "\t\t\t\tmax_box_per_image = config['model']['max_box_per_image'],\n",
        "\t\t\t\tanchors = config['model']['anchors'])\n",
        "\tyolo.load_weights(weights_path)\n",
        "\tif image_path[-4:] == '.mp4':\n",
        "\t\tvideo_out = image_path[:-4] + '_detected' + image_path[-4:]\n",
        "\t\tvideo_reader = cv2.VideoCapture(image_path)\n",
        "\t\tnb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\t\tframe_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\t\tframe_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\t\tvideo_writer = cv2.VideoWriter(video_out,\n",
        "\t\t\t\t\tcv2.VideoWriter_fourcc(*'MPEG'), 50.0, (frame_w, frame_h))\n",
        "\t\tfor i in range(nb_frames):\n",
        "\t\t\t_, image = video_reader.read()\n",
        "\t\t\tboxes = yolo.predict(image)\n",
        "\t\t\timage = draw_boxes(image, boxes, config['model']['labels'])\n",
        "\t\t\tvideo_writer.write(np.uint8(image))\n",
        "\t\tvideo_reader.release()\n",
        "\t\tvideo_writer.release()\n",
        "\telse:\n",
        "\t\timage = cv2.imread(image_path)\n",
        "\t\tboxes = yolo.predict(image)\n",
        "\t\timage = draw_boxes(image, boxes, config['model']['labels'])\n",
        "\t\tprint(len(boxes), 'boxes are found')\n",
        "\t\t#cv2.imwrite(image_path[:-4] + '_detected' + image_path[-4:], image)\n",
        "\t\t# Show image and boxes\n",
        "\t\tplt.figure(figsize=(10,10))\n",
        "\t\tinput_image = cv2.resize(image, (416, 416))\n",
        "\t\tinput_image = input_image / 255.\n",
        "\t\tinput_image = input_image[:,:,::-1]\n",
        "\t\tplt.imshow(image[:,:,::-1]); plt.show()\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RSQTXkrArXDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Detect"
      ]
    },
    {
      "metadata": {
        "id": "TRUBniHCTzyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict('cell.h5', './dataset/Images/Cell001.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}